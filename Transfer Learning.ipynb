{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (8.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Putting data in proper shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (209, 64, 64, 3)\n",
      "train_set_y shape: (209, 1)\n",
      "test_set_x shape: (50, 64, 64, 3)\n",
      "test_set_y shape: (50, 1)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = h5py.File('./data/train.h5', \"r\")\n",
    "train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # train set features\n",
    "train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # train set labels\n",
    "\n",
    "test_dataset = h5py.File('./data/test.h5', \"r\")\n",
    "test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # test set features\n",
    "test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # test set labels\n",
    "\n",
    "train_set_y = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "test_set_y = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "# m_train = train_set_x_orig.shape[0]\n",
    "# m_test = test_set_x_orig.shape[0]\n",
    "# num_px = train_set_x_orig.shape[1]\n",
    "\n",
    "train_set_y = train_set_y.T\n",
    "test_set_y = test_set_y.T\n",
    "\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Standardizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_orig/255.\n",
    "test_set_x = test_set_x_orig/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Resizing 64x64 images to 224x224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x shape: (209, 224, 224, 3)\n",
      "train_set_y shape: (209, 1)\n",
      "test_set_x shape: (50, 224, 224, 3)\n",
      "test_set_y shape: (50, 1)\n"
     ]
    }
   ],
   "source": [
    "train_set_x = np.array([cv2.resize(x, dsize=(224,224)) for x in train_set_x])\n",
    "test_set_x = np.array([cv2.resize(x, dsize=(224,224)) for x in test_set_x])\n",
    "\n",
    "print (\"train_set_x shape: \" + str(train_set_x.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function\n",
    "def evaluate_this_model(model, epochs):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "\n",
    "    history = model.fit(train_set_x, train_set_y, epochs=epochs)\n",
    "    results = model.evaluate(test_set_x, test_set_y)\n",
    "    \n",
    "    plt.plot(np.squeeze(history.history[\"loss\"]))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n\\nAccuracy on training set is {}\".format(history.history[\"acc\"][-1]))\n",
    "    print(\"\\nAccuracy on test set is {}\".format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning on a Keras built-in Model\n",
    "\n",
    "Keras provides pre-trained models to use for transfer learning. For a detailed API, visit [Keras Applications](https://keras.io/applications/). For this class, we're using [MobileNet](https://arxiv.org/pdf/1704.04861.pdf) implementation in Keras which is a fast and effiecient ConvNet optimized for mobile devices.\n",
    "\n",
    "After importing the model from `keras.applications`, we'll initialize the model using `MobileNet(weights=\"imagenet\", input_shape=(224,224,3), include_top=False)` initializor. Here `include_top` means whether to include pre-trained dense layers or discard them. As we are planning to use pretrained conv layers and train our own dense layers, we're setting this argument to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen = MobileNet(weights=\"imagenet\", input_shape=(224,224,3), include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "frozen.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Defining our dense layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = frozen.output\n",
    "trainable = GlobalAveragePooling2D()(trainable)\n",
    "trainable = Dense(128, activation=\"relu\")(trainable)\n",
    "trainable = Dense(32, activation=\"relu\")(trainable)\n",
    "trainable = Dense(1, activation=\"sigmoid\")(trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Appending our layers after pretrained conv layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=frozen.input, outputs=trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, 225, 225, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 112, 112, 32)      864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (ReLU)            (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)      288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 112, 112, 32)      128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)        (None, 112, 112, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 112, 112, 64)      2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 112, 112, 64)      256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)        (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, 113, 113, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 56, 56, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)        (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 56, 56, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 56, 56, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 56, 56, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)        (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, 57, 57, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)        (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 28, 28, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 28, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)        (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, 29, 29, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)        (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 14, 14, 512)       131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)        (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 14, 14, 512)       4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 14, 14, 512)       2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 7, 7, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)       (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 7, 7, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 7, 7, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 7, 7, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 7, 7, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)       (None, 7, 7, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 3,364,225\n",
      "Trainable params: 3,342,337\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Freezing weights of all layers except our dense layers, which are last four layers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x1d7a4d98ba8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x1d7a4d98eb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a4d98e10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a4d9eeb8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a4d9eb00>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7a4df5e10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a4e139e8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b5d50b00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7b5db9e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b5dffe10>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b5ea5e48>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x1d7b5f18dd8>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7b5efbc50>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b5fcaa20>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b5fcad68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7b5ff09e8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b6012e10>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b60bdf60>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7b6112e80>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b612aeb8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b6178320>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7b61ddd30>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b6225518>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b62d0828>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x1d7b6343e10>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7b6326ac8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b63f2898>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b63f2be0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7b6417860>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b643a5c0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b64e1b38>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7b6553fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b6539e48>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b65e4eb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7b6607ba8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b6653390>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7b66f76a0>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x1d7b65535f8>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7b674ec18>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a49bf9e8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a49bf908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a0babeb8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d79e2986a0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a49b8eb8>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7a0bb28d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7b678cb00>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a1197c88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a11ba9b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a1200240>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a124a7f0>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7a12d1b00>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a12f4dd8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a139beb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a13c3780>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a140d0b8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a145a470>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7a14e78d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a150a630>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a15b1ac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a15d8f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a161ee48>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a1670390>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7a16d7a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a171e400>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a17c4b00>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a17fbd68>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a181bb70>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a185e470>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7a18ec860>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a1934a20>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a1981048>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a19da550>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a1a30ef0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a1ad6dd8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x1d7a1b00550>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7a1b00fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a1bf32b0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a1bf3f60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a1c21be0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a1c479e8>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a1cf2d30>,\n",
       " <keras.layers.convolutional.DepthwiseConv2D at 0x1d7a1d1a6d8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a1d61048>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a1e0ddd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1d7a1e40e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x1d7a1e60cc0>,\n",
       " <keras.layers.advanced_activations.ReLU at 0x1d7a1ecf160>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x1d7b7f39f60>,\n",
       " <keras.layers.core.Dense at 0x1d7b7f39da0>,\n",
       " <keras.layers.core.Dense at 0x1d7b7f25da0>,\n",
       " <keras.layers.core.Dense at 0x1d7b7ee5c50>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:-4]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000001D7A4D98BA8> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D7A4D98EB8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A4D98E10> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A4D9EEB8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A4D9EB00> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A4DF5E10> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A4E139E8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B5D50B00> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7B5DB9E48> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B5DFFE10> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B5EA5E48> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D7B5F18DD8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7B5EFBC50> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B5FCAA20> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B5FCAD68> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7B5FF09E8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B6012E10> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B60BDF60> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7B6112E80> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B612AEB8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B6178320> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7B61DDD30> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B6225518> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B62D0828> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D7B6343E10> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7B6326AC8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B63F2898> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B63F2BE0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7B6417860> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B643A5C0> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B64E1B38> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7B6553FD0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B6539E48> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B65E4EB8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7B6607BA8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B6653390> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7B66F76A0> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D7B65535F8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7B674EC18> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A49BF9E8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A49BF908> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A0BABEB8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D79E2986A0> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A49B8EB8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A0BB28D0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B678CB00> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A1197C88> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A11BA9B0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A1200240> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A124A7F0> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A12D1B00> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A12F4DD8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A139BEB8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A13C3780> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A140D0B8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A145A470> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A14E78D0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A150A630> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A15B1AC8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A15D8F98> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A161EE48> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A1670390> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A16D7A90> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A171E400> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A17C4B00> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A17FBD68> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A181BB70> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A185E470> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A18EC860> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A1934A20> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A1981048> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A19DA550> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A1A30EF0> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A1AD6DD8> False\n",
      "<keras.layers.convolutional.ZeroPadding2D object at 0x000001D7A1B00550> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A1B00FD0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A1BF32B0> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A1BF3F60> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A1C21BE0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A1C479E8> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A1CF2D30> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A1D1A6D8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A1D61048> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A1E0DDD8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A1E40E48> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A1E60CC0> False\n",
      "<keras.layers.advanced_activations.ReLU object at 0x000001D7A1ECF160> False\n",
      "<keras.layers.pooling.GlobalAveragePooling2D object at 0x000001D7B7F39F60> True\n",
      "<keras.layers.core.Dense object at 0x000001D7B7F39DA0> True\n",
      "<keras.layers.core.Dense object at 0x000001D7B7F25DA0> True\n",
      "<keras.layers.core.Dense object at 0x000001D7B7EE5C50> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "opt = Adam(lr=learning_rate)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "209/209 [==============================] - 21s 99ms/step - loss: 1.0520 - acc: 0.3923\n",
      "Epoch 2/20\n",
      "209/209 [==============================] - 20s 97ms/step - loss: 0.6811 - acc: 0.6172\n",
      "Epoch 3/20\n",
      "209/209 [==============================] - 23s 109ms/step - loss: 0.5883 - acc: 0.6794\n",
      "Epoch 4/20\n",
      "209/209 [==============================] - 25s 121ms/step - loss: 0.4909 - acc: 0.8134\n",
      "Epoch 5/20\n",
      "209/209 [==============================] - 23s 111ms/step - loss: 0.4358 - acc: 0.8373\n",
      "Epoch 6/20\n",
      "209/209 [==============================] - 24s 116ms/step - loss: 0.3857 - acc: 0.8852\n",
      "Epoch 7/20\n",
      "209/209 [==============================] - 26s 125ms/step - loss: 0.3180 - acc: 0.9234\n",
      "Epoch 8/20\n",
      "209/209 [==============================] - 25s 120ms/step - loss: 0.2810 - acc: 0.9282\n",
      "Epoch 9/20\n",
      "209/209 [==============================] - 22s 106ms/step - loss: 0.2626 - acc: 0.9187\n",
      "Epoch 10/20\n",
      "209/209 [==============================] - 24s 114ms/step - loss: 0.2365 - acc: 0.9474\n",
      "Epoch 11/20\n",
      "209/209 [==============================] - 24s 115ms/step - loss: 0.1805 - acc: 0.9856\n",
      "Epoch 12/20\n",
      "209/209 [==============================] - 26s 125ms/step - loss: 0.1681 - acc: 0.9761\n",
      "Epoch 13/20\n",
      "209/209 [==============================] - 23s 112ms/step - loss: 0.1585 - acc: 0.9761\n",
      "Epoch 14/20\n",
      "209/209 [==============================] - 24s 113ms/step - loss: 0.1383 - acc: 0.9665\n",
      "Epoch 15/20\n",
      "209/209 [==============================] - 27s 127ms/step - loss: 0.1179 - acc: 0.9856\n",
      "Epoch 16/20\n",
      "209/209 [==============================] - 24s 115ms/step - loss: 0.1123 - acc: 0.9856\n",
      "Epoch 17/20\n",
      "209/209 [==============================] - 26s 122ms/step - loss: 0.1004 - acc: 0.9809\n",
      "Epoch 18/20\n",
      "209/209 [==============================] - 28s 136ms/step - loss: 0.0940 - acc: 0.9904\n",
      "Epoch 19/20\n",
      "209/209 [==============================] - 28s 132ms/step - loss: 0.0976 - acc: 0.9856\n",
      "Epoch 20/20\n",
      "209/209 [==============================] - 27s 129ms/step - loss: 0.0831 - acc: 0.9856\n",
      "50/50 [==============================] - 5s 103ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy on training set is 0.9856459332995438\n",
      "\n",
      "Accuracy on test set is 0.9599999904632568\n"
     ]
    }
   ],
   "source": [
    "evaluate_this_model(model, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning on a model from Github\n",
    "\n",
    "Apart from pretrained models provided by Keras, people often tend to implement new models and publish them on github. If developed in Keras, they usually follow the same API provided by Keras. Here, we're using [ShuffleNet](https://github.com/scheckmedia/keras-shufflenet) which is not provided by Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shufflenet import ShuffleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen2 = ShuffleNet(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 24) 648         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 56, 56, 24)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_gconv_1 (Conv (None, 56, 56, 36)   864         maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_gconv_1 (Batch (None, 56, 56, 36)   144         stage2/block1/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_gconv_1 (Act (None, 56, 56, 36)   0           stage2/block1/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/channel_shuffle ( (None, 56, 56, 36)   0           stage2/block1/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block1/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_gconv_2 (Conv (None, 28, 28, 120)  4320        stage2/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_gconv_2 (Batch (None, 28, 28, 120)  480         stage2/block1/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/avg_pool (Average (None, 28, 28, 24)   0           maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/concat (Concatena (None, 28, 28, 144)  0           stage2/block1/bn_gconv_2[0][0]   \n",
      "                                                                 stage2/block1/avg_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_out (Activat (None, 28, 28, 144)  0           stage2/block1/concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block2/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block2/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block2/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block2/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block2/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/add (Add)         (None, 28, 28, 144)  0           stage2/block2/bn_gconv_2[0][0]   \n",
      "                                                                 stage2/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_out (Activat (None, 28, 28, 144)  0           stage2/block2/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block3/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block3/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block3/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block3/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block3/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/add (Add)         (None, 28, 28, 144)  0           stage2/block3/bn_gconv_2[0][0]   \n",
      "                                                                 stage2/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_out (Activat (None, 28, 28, 144)  0           stage2/block3/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block4/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block4/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block4/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block4/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block4/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/add (Add)         (None, 28, 28, 144)  0           stage2/block4/bn_gconv_2[0][0]   \n",
      "                                                                 stage2/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_out (Activat (None, 28, 28, 144)  0           stage2/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_gconv_1 (Conv (None, 28, 28, 72)   10368       stage2/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_gconv_1 (Batch (None, 28, 28, 72)   288         stage3/block1/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_gconv_1 (Act (None, 28, 28, 72)   0           stage3/block1/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/channel_shuffle ( (None, 28, 28, 72)   0           stage3/block1/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block1/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_gconv_2 (Conv (None, 14, 14, 144)  10368       stage3/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_gconv_2 (Batch (None, 14, 14, 144)  576         stage3/block1/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/avg_pool (Average (None, 14, 14, 144)  0           stage2/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/concat (Concatena (None, 14, 14, 288)  0           stage3/block1/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block1/avg_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_out (Activat (None, 14, 14, 288)  0           stage3/block1/concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block2/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block2/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block2/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block2/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block2/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/add (Add)         (None, 14, 14, 288)  0           stage3/block2/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_out (Activat (None, 14, 14, 288)  0           stage3/block2/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block3/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block3/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block3/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block3/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block3/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/add (Add)         (None, 14, 14, 288)  0           stage3/block3/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_out (Activat (None, 14, 14, 288)  0           stage3/block3/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block4/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block4/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block4/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block4/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block4/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/add (Add)         (None, 14, 14, 288)  0           stage3/block4/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_out (Activat (None, 14, 14, 288)  0           stage3/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block5/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block5/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block5/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block5/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block5/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block5/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/add (Add)         (None, 14, 14, 288)  0           stage3/block5/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_out (Activat (None, 14, 14, 288)  0           stage3/block5/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block5/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block6/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block6/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block6/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block6/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block6/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block6/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/add (Add)         (None, 14, 14, 288)  0           stage3/block6/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block5/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_out (Activat (None, 14, 14, 288)  0           stage3/block6/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block6/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block7/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block7/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block7/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block7/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block7/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block7/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/add (Add)         (None, 14, 14, 288)  0           stage3/block7/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block6/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_out (Activat (None, 14, 14, 288)  0           stage3/block7/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block7/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block8/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block8/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block8/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block8/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block8/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block8/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/add (Add)         (None, 14, 14, 288)  0           stage3/block8/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block7/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_out (Activat (None, 14, 14, 288)  0           stage3/block8/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1 (Conv (None, 14, 14, 144)  41472       stage3/block8/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_gconv_1 (Batch (None, 14, 14, 144)  576         stage4/block1/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_gconv_1 (Act (None, 14, 14, 144)  0           stage4/block1/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/channel_shuffle ( (None, 14, 14, 144)  0           stage4/block1/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block1/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2 (Conv (None, 7, 7, 288)    41472       stage4/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_gconv_2 (Batch (None, 7, 7, 288)    1152        stage4/block1/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/avg_pool (Average (None, 7, 7, 288)    0           stage3/block8/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/concat (Concatena (None, 7, 7, 576)    0           stage4/block1/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block1/avg_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_out (Activat (None, 7, 7, 576)    0           stage4/block1/concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block2/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block2/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block2/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block2/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block2/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/add (Add)         (None, 7, 7, 576)    0           stage4/block2/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_out (Activat (None, 7, 7, 576)    0           stage4/block2/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block3/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block3/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block3/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block3/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block3/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/add (Add)         (None, 7, 7, 576)    0           stage4/block3/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_out (Activat (None, 7, 7, 576)    0           stage4/block3/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block4/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block4/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block4/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block4/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block4/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/add (Add)         (None, 7, 7, 576)    0           stage4/block4/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_out (Activat (None, 7, 7, 576)    0           stage4/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "global_pool (GlobalMaxPooling2D (None, 576)          0           stage4/block4/relu_out[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 969,528\n",
      "Trainable params: 954,888\n",
      "Non-trainable params: 14,640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "frozen2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable2 = frozen2.output\n",
    "trainable2 = Dense(128, activation=\"relu\")(trainable2)\n",
    "trainable2 = Dense(32, activation=\"relu\")(trainable2)\n",
    "trainable2 = Dense(1, activation=\"sigmoid\")(trainable2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 24) 648         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "maxpool1 (MaxPooling2D)         (None, 56, 56, 24)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_gconv_1 (Conv (None, 56, 56, 36)   864         maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_gconv_1 (Batch (None, 56, 56, 36)   144         stage2/block1/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_gconv_1 (Act (None, 56, 56, 36)   0           stage2/block1/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/channel_shuffle ( (None, 56, 56, 36)   0           stage2/block1/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block1/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/1x1_gconv_2 (Conv (None, 28, 28, 120)  4320        stage2/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/bn_gconv_2 (Batch (None, 28, 28, 120)  480         stage2/block1/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/avg_pool (Average (None, 28, 28, 24)   0           maxpool1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/concat (Concatena (None, 28, 28, 144)  0           stage2/block1/bn_gconv_2[0][0]   \n",
      "                                                                 stage2/block1/avg_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block1/relu_out (Activat (None, 28, 28, 144)  0           stage2/block1/concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block2/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block2/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block2/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block2/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block2/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/add (Add)         (None, 28, 28, 144)  0           stage2/block2/bn_gconv_2[0][0]   \n",
      "                                                                 stage2/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block2/relu_out (Activat (None, 28, 28, 144)  0           stage2/block2/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block3/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block3/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block3/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block3/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block3/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/add (Add)         (None, 28, 28, 144)  0           stage2/block3/bn_gconv_2[0][0]   \n",
      "                                                                 stage2/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block3/relu_out (Activat (None, 28, 28, 144)  0           stage2/block3/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1_gconv_1 (Conv (None, 28, 28, 36)   5184        stage2/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_gconv_1 (Batch (None, 28, 28, 36)   144         stage2/block4/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_gconv_1 (Act (None, 28, 28, 36)   0           stage2/block4/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/channel_shuffle ( (None, 28, 28, 36)   0           stage2/block4/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1_dwconv_1 (Dep (None, 28, 28, 36)   324         stage2/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_dwconv_1 (Batc (None, 28, 28, 36)   144         stage2/block4/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/1x1_gconv_2 (Conv (None, 28, 28, 144)  5184        stage2/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/bn_gconv_2 (Batch (None, 28, 28, 144)  576         stage2/block4/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/add (Add)         (None, 28, 28, 144)  0           stage2/block4/bn_gconv_2[0][0]   \n",
      "                                                                 stage2/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage2/block4/relu_out (Activat (None, 28, 28, 144)  0           stage2/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_gconv_1 (Conv (None, 28, 28, 72)   10368       stage2/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_gconv_1 (Batch (None, 28, 28, 72)   288         stage3/block1/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_gconv_1 (Act (None, 28, 28, 72)   0           stage3/block1/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/channel_shuffle ( (None, 28, 28, 72)   0           stage3/block1/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block1/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/1x1_gconv_2 (Conv (None, 14, 14, 144)  10368       stage3/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/bn_gconv_2 (Batch (None, 14, 14, 144)  576         stage3/block1/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/avg_pool (Average (None, 14, 14, 144)  0           stage2/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/concat (Concatena (None, 14, 14, 288)  0           stage3/block1/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block1/avg_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block1/relu_out (Activat (None, 14, 14, 288)  0           stage3/block1/concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block2/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block2/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block2/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block2/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block2/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/add (Add)         (None, 14, 14, 288)  0           stage3/block2/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block2/relu_out (Activat (None, 14, 14, 288)  0           stage3/block2/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block3/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block3/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block3/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block3/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block3/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/add (Add)         (None, 14, 14, 288)  0           stage3/block3/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block3/relu_out (Activat (None, 14, 14, 288)  0           stage3/block3/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block4/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block4/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block4/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block4/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block4/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/add (Add)         (None, 14, 14, 288)  0           stage3/block4/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block4/relu_out (Activat (None, 14, 14, 288)  0           stage3/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block5/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block5/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block5/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block5/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block5/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block5/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block5/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/add (Add)         (None, 14, 14, 288)  0           stage3/block5/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block5/relu_out (Activat (None, 14, 14, 288)  0           stage3/block5/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block5/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block6/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block6/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block6/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block6/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block6/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block6/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block6/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/add (Add)         (None, 14, 14, 288)  0           stage3/block6/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block5/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block6/relu_out (Activat (None, 14, 14, 288)  0           stage3/block6/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block6/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block7/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block7/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block7/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block7/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block7/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block7/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block7/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/add (Add)         (None, 14, 14, 288)  0           stage3/block7/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block6/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block7/relu_out (Activat (None, 14, 14, 288)  0           stage3/block7/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1_gconv_1 (Conv (None, 14, 14, 72)   20736       stage3/block7/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_gconv_1 (Batch (None, 14, 14, 72)   288         stage3/block8/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_gconv_1 (Act (None, 14, 14, 72)   0           stage3/block8/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/channel_shuffle ( (None, 14, 14, 72)   0           stage3/block8/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1_dwconv_1 (Dep (None, 14, 14, 72)   648         stage3/block8/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_dwconv_1 (Batc (None, 14, 14, 72)   288         stage3/block8/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/1x1_gconv_2 (Conv (None, 14, 14, 288)  20736       stage3/block8/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/bn_gconv_2 (Batch (None, 14, 14, 288)  1152        stage3/block8/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/add (Add)         (None, 14, 14, 288)  0           stage3/block8/bn_gconv_2[0][0]   \n",
      "                                                                 stage3/block7/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage3/block8/relu_out (Activat (None, 14, 14, 288)  0           stage3/block8/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_1 (Conv (None, 14, 14, 144)  41472       stage3/block8/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_gconv_1 (Batch (None, 14, 14, 144)  576         stage4/block1/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_gconv_1 (Act (None, 14, 14, 144)  0           stage4/block1/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/channel_shuffle ( (None, 14, 14, 144)  0           stage4/block1/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block1/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block1/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/1x1_gconv_2 (Conv (None, 7, 7, 288)    41472       stage4/block1/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/bn_gconv_2 (Batch (None, 7, 7, 288)    1152        stage4/block1/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/avg_pool (Average (None, 7, 7, 288)    0           stage3/block8/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/concat (Concatena (None, 7, 7, 576)    0           stage4/block1/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block1/avg_pool[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block1/relu_out (Activat (None, 7, 7, 576)    0           stage4/block1/concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block2/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block2/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block2/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block2/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block2/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block2/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block2/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/add (Add)         (None, 7, 7, 576)    0           stage4/block2/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block1/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block2/relu_out (Activat (None, 7, 7, 576)    0           stage4/block2/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block3/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block3/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block3/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block3/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block3/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block3/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block3/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/add (Add)         (None, 7, 7, 576)    0           stage4/block3/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block2/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block3/relu_out (Activat (None, 7, 7, 576)    0           stage4/block3/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_1 (Conv (None, 7, 7, 144)    82944       stage4/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_gconv_1 (Batch (None, 7, 7, 144)    576         stage4/block4/1x1_gconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_gconv_1 (Act (None, 7, 7, 144)    0           stage4/block4/bn_gconv_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/channel_shuffle ( (None, 7, 7, 144)    0           stage4/block4/relu_gconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_dwconv_1 (Dep (None, 7, 7, 144)    1296        stage4/block4/channel_shuffle[0][\n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_dwconv_1 (Batc (None, 7, 7, 144)    576         stage4/block4/1x1_dwconv_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/1x1_gconv_2 (Conv (None, 7, 7, 576)    82944       stage4/block4/bn_dwconv_1[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/bn_gconv_2 (Batch (None, 7, 7, 576)    2304        stage4/block4/1x1_gconv_2[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/add (Add)         (None, 7, 7, 576)    0           stage4/block4/bn_gconv_2[0][0]   \n",
      "                                                                 stage4/block3/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "stage4/block4/relu_out (Activat (None, 7, 7, 576)    0           stage4/block4/add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "global_pool (GlobalMaxPooling2D (None, 576)          0           stage4/block4/relu_out[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          73856       global_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           4128        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            33          dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,047,545\n",
      "Trainable params: 1,032,905\n",
      "Non-trainable params: 14,640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(inputs=frozen2.input, outputs=trainable2)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model2.layers[:-3]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x000001D7A49ADD68> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A259ACF8> False\n",
      "<keras.layers.pooling.MaxPooling2D object at 0x000001D7A259AA20> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A259AAC8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A257BD68> False\n",
      "<keras.layers.core.Activation object at 0x000001D7A2590668> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7A25A48D0> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7A25820B8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A26B7A20> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A26B7CF8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A26F8D30> False\n",
      "<keras.layers.pooling.AveragePooling2D object at 0x000001D7A2741AC8> False\n",
      "<keras.layers.merge.Concatenate object at 0x000001D7A27D1F28> False\n",
      "<keras.layers.core.Activation object at 0x000001D7A27D1B00> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7B67D2A20> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B689EA90> False\n",
      "<keras.layers.core.Activation object at 0x000001D7B689EA58> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7B68C72E8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7B68C75F8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B69BCEF0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7B69BCE80> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B69FDEF0> False\n",
      "<keras.layers.merge.Add object at 0x000001D7B6AA6CF8> False\n",
      "<keras.layers.core.Activation object at 0x000001D7B6AF4DD8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7B6ACF978> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7B6B5E390> False\n",
      "<keras.layers.core.Activation object at 0x000001D7B6B79BA8> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BE4778D0> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7B6BBB908> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BE573550> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BE5735C0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BE5B6F60> False\n",
      "<keras.layers.merge.Add object at 0x000001D7BE65BDA0> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BE6839E8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BE683668> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BE716400> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BE72EC18> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BE79F940> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7BE770978> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BE891630> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BE891400> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BE8DE9B0> False\n",
      "<keras.layers.merge.Add object at 0x000001D7BE986F98> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BE9AD588> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BE9ADA58> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BEA3E470> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BEA57C88> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BEAC59B0> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7BEA969E8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A2569B70> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7A2569F28> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7A255CC18> False\n",
      "<keras.layers.pooling.AveragePooling2D object at 0x000001D7A2536668> False\n",
      "<keras.layers.merge.Concatenate object at 0x000001D7BEBBAB70> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BEBBABA8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BECC5160> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BED668D0> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BED66E10> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BEDD3E10> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7BEDB7A90> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BEEA7470> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BEEA7E10> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BEEE6780> False\n",
      "<keras.layers.merge.Add object at 0x000001D7BEF354E0> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BEF8F2B0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BEF8FF28> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF0886A0> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BF06F518> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BF0F6DD8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7BF0DCB00> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF1C5400> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BF1C5DA0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF24C4A8> False\n",
      "<keras.layers.merge.Add object at 0x000001D7BF2267B8> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BF2A6908> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BF2A6EB8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF39B630> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BF35AD68> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BF40EE10> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7BF3F2A90> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF4E4470> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BF4E4E10> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF524780> False\n",
      "<keras.layers.merge.Add object at 0x000001D7BF5714E0> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BF5CC2B0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BF5CCF28> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF6C26A0> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BF6A9518> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BF735DD8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7BF71BB00> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF80B4E0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BF80BEF0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF8972E8> False\n",
      "<keras.layers.merge.Add object at 0x000001D7BF870DD8> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BF8F14E0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BF8F1FD0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BF9E6A20> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BF98C358> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BFA54EB8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7BFA3DB00> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BFB2E550> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BFB2EF60> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BFBBD358> False\n",
      "<keras.layers.merge.Add object at 0x000001D7BFB92E48> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BFC1A550> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BFC1AF60> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BFD11780> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BFCFA5F8> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7BFD7FEB8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7BFD68B70> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BFE585C0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BFE58D68> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7BFE9A5F8> False\n",
      "<keras.layers.merge.Add object at 0x000001D7BFEE6438> False\n",
      "<keras.layers.core.Activation object at 0x000001D7BFF352B0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7BFF35CC0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C00297F0> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C0011668> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7C0097D68> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7C007CBE0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C016D630> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C016DDD8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C0201978> False\n",
      "<keras.layers.merge.Add object at 0x000001D7C01D0E10> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C02888D0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C0258BE0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C034F898> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C02F50B8> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7C03BFE10> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7C03A6C50> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C04966A0> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C0496E48> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C0527748> False\n",
      "<keras.layers.pooling.AveragePooling2D object at 0x000001D7C04FBFD0> False\n",
      "<keras.layers.merge.Concatenate object at 0x000001D7C0582BA8> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C0582518> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C05D35F8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C0678B38> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C06CE400> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7C069EEB8> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7C069E5C0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C07BDA58> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C07BDD30> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C0800D68> False\n",
      "<keras.layers.merge.Add object at 0x000001D7C0849B00> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C08A5D68> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C0914D30> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C2951EF0> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C2929C50> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7C299B470> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7C2976940> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C2A977B8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C2A97DA0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C2AD7DD8> False\n",
      "<keras.layers.merge.Add object at 0x000001D7C2B23B70> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C2B7FDD8> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C2BEDDD8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C2C77D30> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C2C113C8> False\n",
      "<keras.layers.core.Lambda object at 0x000001D7C2CC34E0> False\n",
      "<keras.layers.convolutional.DepthwiseConv2D object at 0x000001D7C2C9F9B0> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C2DBC828> False\n",
      "<keras.layers.convolutional.Conv2D object at 0x000001D7C2DBCE10> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x000001D7C2E00E10> False\n",
      "<keras.layers.merge.Add object at 0x000001D7C2E4A3C8> False\n",
      "<keras.layers.core.Activation object at 0x000001D7C2EA6AC8> False\n",
      "<keras.layers.pooling.GlobalMaxPooling2D object at 0x000001D7C2F18E10> False\n",
      "<keras.layers.core.Dense object at 0x000001D7C2FEF4E0> True\n",
      "<keras.layers.core.Dense object at 0x000001D7C2FEF588> True\n",
      "<keras.layers.core.Dense object at 0x000001D7C2FEF6D8> True\n"
     ]
    }
   ],
   "source": [
    "for layer in model2.layers:\n",
    "    print(layer, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "opt = Adam(lr=learning_rate)\n",
    "model2.compile(optimizer=opt,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "209/209 [==============================] - 10s 48ms/step - loss: 1.0151 - acc: 0.5789\n",
      "Epoch 2/10\n",
      "209/209 [==============================] - 6s 28ms/step - loss: 0.7175 - acc: 0.5359\n",
      "Epoch 3/10\n",
      "209/209 [==============================] - 6s 28ms/step - loss: 0.6501 - acc: 0.6364\n",
      "Epoch 4/10\n",
      "209/209 [==============================] - 8s 38ms/step - loss: 0.5691 - acc: 0.7033\n",
      "Epoch 5/10\n",
      "209/209 [==============================] - 9s 43ms/step - loss: 0.6303 - acc: 0.6124\n",
      "Epoch 6/10\n",
      "209/209 [==============================] - 6s 27ms/step - loss: 0.5482 - acc: 0.6938\n",
      "Epoch 7/10\n",
      "209/209 [==============================] - 9s 43ms/step - loss: 0.5570 - acc: 0.6746\n",
      "Epoch 8/10\n",
      "209/209 [==============================] - 9s 42ms/step - loss: 0.5921 - acc: 0.6699\n",
      "Epoch 9/10\n",
      "209/209 [==============================] - 6s 28ms/step - loss: 0.6267 - acc: 0.6746\n",
      "Epoch 10/10\n",
      "209/209 [==============================] - 9s 43ms/step - loss: 0.5469 - acc: 0.6938\n",
      "50/50 [==============================] - 2s 40ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy on training set is 0.6937799063025479\n",
      "\n",
      "Accuracy on test set is 0.34\n"
     ]
    }
   ],
   "source": [
    "evaluate_this_model(model2, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
